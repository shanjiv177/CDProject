\documentclass[12pt]{article}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{verbose, a4paper, tmargin=1.3in, bmargin=0.85in, lmargin=0.85in, rmargin=0.85in}
\usepackage{lscape}
\usepackage{lineno,hyperref}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{epsfig}
\usepackage{amsmath}  
\usepackage{amsfonts}
\usepackage{amsthm} 
\usepackage{amssymb}
\usepackage{placeins}
\usepackage{multirow}
\usepackage[export]{adjustbox}[2011/08/13]
\usepackage{tabularx}
\usepackage{caption}
\usepackage{epsf}
\usepackage{epstopdf}
\usepackage{subfigure} 
\usepackage{colortbl}
\usepackage{longtable}
\usepackage{enumerate}
\usepackage{tabularx, booktabs}
\usepackage{url}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{float}
\usepackage{enumitem}

\usepackage{longtable}
\usepackage{color}
\definecolor{highlight}{RGB}{255, 255, 204}


\usepackage{multirow}
\usepackage[flushleft]{threeparttable}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{array, makecell}
\usepackage{hhline}
\usepackage{longtable}
\usepackage{tabularray}
\usepackage[table,xcdraw]{xcolor}
\usepackage{caption}

% Page Border
\usepackage{tikz}
\usetikzlibrary{calc}
\newcommand\HRule{\rule{\textwidth}{1pt}}
\usepackage{tabularx}
\usepackage{longtable}
\newcolumntype{P}[1]{>{\centering\arraybackslash}m{#1}}
\usepackage{tcolorbox}
% To set Figure Caption and Text Gap
\setlength\belowcaptionskip{2ex}
% \linespread{1.1}


\newlength{\defbaselineskip}
\setlength{\defbaselineskip}{\baselineskip}
\newcommand{\setlinespacing}[1]{\setlength{\baselineskip}{#1 \defbaselineskip}}

\usepackage{makecell}
\newcounter{qcounter}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{multirow}
\usepackage{xcolor}

% Table caption below the table
\begin{document}
\begin{titlepage}
%\setlinespacing{1.5}
\setlinespacing{2}
\thispagestyle{empty}

\begin{center}
%26.4 
{\fontsize{22}{26.4}\textbf{A Report on\\ Compiler Design Lab (CS304): Mini Project Phase 1}}\\
% \vspace{1cm}

% \textbf{in}\\

\textbf{by}\\
{\textbf{Shanjiv A}} (Roll No: 231CS155)\\
\vspace{0.5cm}
{\textbf{Prabhav S Korwar}} (Roll No: 231CS141)\\
\vspace{0.5cm}
{\textbf{Akshaj PVY}} (Roll No: 231CS1xx)\\


\vspace{0.3cm}
\begin{figure}[h] 
{\centering {\includegraphics[height=4.5cm]{nitk_logo.png}}\par}
\end{figure} 

\setlinespacing{2}
\vspace{0.3cm}

% {\textbf{Department of Computer Science and Engineering}\par}
% {\textbf{National Institute of Technology Karnataka, Surathkal}\par}
% {\textbf{Mangaluru-575025, India}\par}

% {\textbf{\monthname -2023}\par}

{\textbf{DEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING}\par}
\vspace{-12pt}
{\textbf{NATIONAL INSTITUTE OF TECHNOLOGY KARNATAKA}\par}
\vspace{-12pt}
{\textbf{SURATHKAL, MANGALURU-575025}\par}
\vspace{-12pt}
{\textbf{13-August-2025}\par}



\end{center}
\pagebreak
\end{titlepage}













\section{Introduction} 

\subsection{Lexical Analysis}
Lexical analysis is the first phase of a compiler, which takes the source code as input and produces a sequence of tokens as output. A lexical analyzer, or scanner, reads the input characters of the source code, identifies the lexemes, and produces the corresponding tokens. This process is typically implemented using deterministic finite automata (DFA).

In this project, we have implemented a lexical analyzer for the C programming language using Flex, a scanner generator tool that converts a lexical specification into a C program that performs pattern matching on text. Our scanner recognizes standard C tokens, maintains symbol and constant tables, and provides detailed information about the code structure.

\subsection{Tokens \& Lexemes}
A token is a categorized block of text in the source code. Each token has:
\begin{itemize}
    \item A token type or category (e.g., keyword, identifier, operator)
    \item The actual string value or lexeme (e.g., "if", "main", "+")
\end{itemize}

Our scanner identifies the following token types:
\begin{itemize}
    \item Keywords (if, while, return, etc.)
    \item Identifiers (variable and function names)
    \item Constants (numeric literals, string literals, character literals)
    \item Operators (+, -, *, /, etc.)
    \item Punctuation (;, {, }, etc.)
    \item Preprocessor directives (\#include, \#define)
\end{itemize}

\section{Overview of the Code}

Our lexical analyzer for the C programming language is implemented using Flex and provides comprehensive token recognition and tracking capabilities. The scanner is organized into several key components:

\subsection{Key Components}
\begin{itemize}
    \item \textbf{Symbol Table}: A hash-based implementation with O(1) lookup that tracks identifiers, their types, dimensions, frequencies, and function-related information.
    
    \item \textbf{Constant Table}: Tracks constant values with their variable names, line numbers, and types.
    
    \item \textbf{State Tracking}: Maintains context for declarations, assignments, and function argument collection using various state variables.
    
    \item \textbf{Lexical Rules}: Defines regular expressions for token patterns and associates actions with each pattern to maintain tables and context.
    
    \item \textbf{Error Handling}: Detects and reports invalid tokens with line numbers, allowing the scanner to find multiple errors in a single pass.
\end{itemize}

\subsection{Data Structures}
The main data structures used in the scanner are:

\subsubsection{Symbol Structure}
\begin{verbatim}
typedef struct Symbol {
    char* name;
    char* type;         
    char* dimensions;   
    int   frequency;    
    char* return_type;  
    char* param_lists;  
    int   is_function;  
    struct Symbol* next;
} Symbol;
\end{verbatim}

\subsubsection{Constant Structure}
\begin{verbatim}
typedef struct Constant {
    char* var_name; 
    int   line;
    char* value;
    char* type; 
} Constant;
\end{verbatim}

\section{Scanner Implementation}

\subsection{Key Algorithms}

\subsubsection{Symbol Table Hash Function}
We use the DJB2 hash algorithm for the symbol table, which provides good distribution for string keys with minimal collisions:

\begin{verbatim}
static unsigned long hash_function(const char* str) {
    unsigned long hash = 5381;
    int c;
    while ((c = (unsigned char) *str++)) {
        hash = ((hash << 5) + hash) + c; // hash * 33 + c
    }
    return hash;
}
\end{verbatim}

\subsubsection{Function Argument Collection}
The scanner uses a state machine to collect function arguments:
\begin{enumerate}
    \item When a function call is detected, enters \texttt{FUNCARGS} state
    \item Collects all text between parentheses
    \item Handles nested parentheses by tracking depth
    \item When the closing parenthesis is found, processes the collected arguments
\end{enumerate}

\subsubsection{Variable Assignment Tracking}
For tracking variable assignments:
\begin{enumerate}
    \item When an identifier is found, it's stored in \texttt{last\_ident}
    \item When \texttt{=} is encountered after an identifier, \texttt{in\_assignment} is set
    \item The current variable name is stored in \texttt{current\_var}
    \item When a constant is found during assignment, it's associated with the variable
\end{enumerate}

\section{List of Recognized Tokens and Their Meaning}

\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Token Type} & \textbf{Examples} & \textbf{Description} \\
\hline
KEYWORD & \texttt{if}, \texttt{while}, \texttt{return} & C language reserved words \\
\hline
TYPE & \texttt{int}, \texttt{float}, \texttt{char} & Built-in C data types \\
\hline
IDENT & Variable and function names & Matches \texttt{[a-zA-Z\_][a-zA-Z0-9\_]*} \\
\hline
NUMBER & \texttt{123}, \texttt{3.14} & Integer and floating-point literals \\
\hline
STRING & \texttt{"Hello World"} & String literals in double quotes \\
\hline
CHAR & \texttt{'a'} & Character literals in single quotes \\
\hline
OP & \texttt{+}, \texttt{-}, \texttt{*}, \texttt{/}, \texttt{=} & Arithmetic and assignment operators \\
\hline
PUNCT & \texttt{;}, \texttt{\{}, \texttt{\}}, \texttt{(}, \texttt{)} & Punctuation marks and delimiters \\
\hline
PREPROC & \texttt{\#include}, \texttt{\#define} & Preprocessor directives \\
\hline
STRING & \texttt{"Hello World"} & Text between double quotes \\
\hline
CHAR & \texttt{'a'}, \texttt{'\textbackslash n'} & Single characters with escape sequences \\
\hline
NUMBER & \texttt{123}, \texttt{0xFF}, \texttt{3.14} & Numeric literals \\
\hline
OP & \texttt{+}, \texttt{-}, \texttt{==}, \texttt{!=} & Arithmetic, comparison, logical operators \\
\hline
PUNCT & \texttt{;}, \texttt{\{}, \texttt{\}}, \texttt{(} & Separators and delimiters \\
\hline
PREPROC & \texttt{\#include}, \texttt{\#define} & C preprocessor directives \\
\hline
\end{tabular}
\end{center}
\section{Deterministic Finite Automata (DFA) for Token Recognition}

Our scanner is implemented using a collection of Deterministic Finite Automata (DFAs), each responsible for recognizing specific token patterns. This section presents the formal state diagrams for the key token recognition mechanisms.

\subsection{Main Scanner States}

The lexical analyzer operates in multiple states, with transitions triggered by specific character sequences. The figure below shows the primary scanner states and the transitions between them:

\begin{figure}[H]
\centering
\begin{tikzpicture}[
    node distance=7cm and 5cm, 
    auto, 
    thick, 
    state/.style={circle, draw, minimum size=1.8cm},
    accepting/.style={double}
]
    % Nodes with greatly increased spacing
    \node[state, initial, fill=blue!10] (q0) at (0,0) {INITIAL};
    \node[state, fill=red!10] (q1) at (9,5) {COMMENT};
    \node[state, fill=green!10] (q2) at (9,0) {STRING};
    \node[state, fill=yellow!10] (q3) at (9,-3) {CHARLIT};
    \node[state, fill=purple!10] (q4) at (0,6) {PP};
    \node[state, fill=orange!10] (q5) at (0,-6) {FUNCARGS};
    
    % Comment transitions - adjusted to avoid crossing nodes
    \draw[->, thick] (q0) to[out=45, in=180] node[above] {\texttt{/*}} (q1);
    \draw[->, thick] (q1) to[out=215, in=45] node[left] {\texttt{*/}} (q0);
    \draw[->, thick] (q1) edge[loop right] node {any except \texttt{*/}} (q1);
    
    % String transitions
    \draw[->, thick] (q0) -- node[above] {\texttt{\"}} (q2);
    \draw[->, thick] (q2) -- node[below] {\texttt{\"}} (q0);
    \draw[->, thick] (q2) edge[loop right] node {any except \texttt{\"}} (q2);
    
    % Character literal transitions - adjusted
    \draw[->, thick] (q0) to[out=315, in=180] node[below] {\texttt{'}} (q3);
    \draw[->, thick] (q3) to[out=180, in=315] node[above] {\texttt{'}} (q0);
    \draw[->, thick] (q3) edge[loop right] node {any except \texttt{'}} (q3);
    
    % Preprocessor transitions
    \draw[->, thick] (q0) to[out=90, in=270] node[left] {\texttt{\#}} (q4);
    \draw[->, thick] (q4) to[out=270, in=90] node[right] {\texttt{end of line}} (q0);
    \draw[->, thick] (q4) edge[loop above] node {any except newline} (q4);
    
    % Function arguments transitions
    \draw[->, thick] (q0) to[out=270, in=90] node[left] {\texttt{ident(}} (q5);
    \draw[->, thick] (q5) to[out=90, in=270] node[right] {\texttt{balanced )}} (q0);
    \draw[->, thick] (q5) edge[loop below] node {any except unbalanced \texttt{)}} (q5);
\end{tikzpicture}
\caption{Main Flex states and transitions in the scanner}
\end{figure}

Each state handles a specific aspect of lexical analysis:
\begin{itemize}
    \item \textbf{INITIAL}: Default state where most tokens are recognized
    \item \textbf{COMMENT}: Activated when entering comments, ignores all content until comment end
    \item \textbf{STRING}: Captures string literals between double quotes
    \item \textbf{CHARLIT}: Captures character literals between single quotes
    \item \textbf{PP}: Handles preprocessor directives starting with \#
    \item \textbf{FUNCARGS}: Collects function arguments between parentheses
\end{itemize}

\subsection{Identifier Recognition DFA}

The DFA below formally describes the pattern used to recognize C identifiers. Identifiers must start with a letter or underscore, followed by zero or more letters, digits, or underscores.

\begin{figure}[H]
\centering
\begin{tikzpicture}[
    node distance=6cm, 
    auto, 
    thick,
    state/.style={circle, draw, minimum size=1.8cm},
    accepting/.style={double}
]
    % Explicitly positioned nodes with much greater spacing
    \node[state, initial, fill=blue!10] (q0) at (0,0) {$q_0$};
    \node[state, accepting, fill=green!10] (q1) at (6,0) {$q_1$};
    
    % Transitions with improved routing
    \draw[->, thick] (q0) to[out=15, in=165] node[above] {[a-zA-Z\_]} (q1);
    \draw[->, thick] (q1) edge[loop above, looseness=8] node {[a-zA-Z0-9\_]} (q1);
    
    % Legend with better positioning and more space
    \node[anchor=west] at (9,0) {
        \begin{tabular}{l}
            \textbf{Pattern:} [a-zA-Z\_][a-zA-Z0-9\_]* \\
            \textbf{Examples:} main, x1, \_count \\
            \textbf{Token:} IDENT
        \end{tabular}
    };
\end{tikzpicture}
\caption{DFA for identifier recognition with examples}
\end{figure}

\subsection{Number Recognition DFA}

The following DFA recognizes integers, floating-point numbers, and numbers in scientific notation. It includes states for the integer part, decimal part, and exponent part.

\begin{figure}[H]
\centering
\begin{tikzpicture}[
    node distance=4cm, 
    auto, 
    thick,
    state/.style={circle, draw, minimum size=1.5cm},
    accepting/.style={double}
]
    % Explicitly positioned nodes with much greater spacing
    \node[state, initial, fill=blue!10] (q0) at (0,0) {$q_0$};
    \node[state, accepting, fill=green!10] (q1) at (4,0) {$q_1$};
    \node[state, accepting, fill=green!10] (q2) at (8,0) {$q_2$};
    \node[state, fill=yellow!10] (q3) at (12,0) {$q_3$};
    \node[state, accepting, fill=green!10] (q4) at (16,0) {$q_4$};
    
    % Transitions with improved routing to avoid crossing nodes
    \draw[->, thick] (q0) -- node[above] {[0-9]} (q1);
    \draw[->, thick] (q1) edge[loop above] node {[0-9]} (q1);
    \draw[->, thick] (q1) -- node[above] {.} (q2);
    \draw[->, thick] (q2) edge[loop above] node {[0-9]} (q2);
    \draw[->, thick] (q2) -- node[above] {e|E} (q3);
    \draw[->, thick] (q3) -- node[above] {[0-9]} (q4);
    \draw[->, thick] (q3) to[out=135, in=45, looseness=1.5] node[above] {+|-} (q3);
    \draw[->, thick] (q4) edge[loop above] node {[0-9]} (q4);
    
    % Legend with better positioning
    \node[anchor=north] at (8,-2) {
        \begin{tabular}{l}
            \textbf{States:} \\
            $q_0$: Start \\
            $q_1$: Integer part (accepting) \\
            $q_2$: Fractional part (accepting) \\
            $q_3$: Exponent sign \\
            $q_4$: Exponent digits (accepting)
        \end{tabular}
    };
\end{tikzpicture}
\caption{DFA for numeric literals recognition}
\end{figure}

Examples recognized by this DFA:
\begin{itemize}
    \item \textbf{Integer literals:} 42, 123, 0
    \item \textbf{Floating-point literals:} 3.14, 0.5, 1.0
    \item \textbf{Scientific notation:} 1.2e3, 5.4E-2, 1e+10
\end{itemize}

\subsection{String Literal Recognition DFA}

The DFA below models the recognition of string literals. It handles escape sequences and ensures proper string termination.

\begin{figure}[H]
\centering
\begin{tikzpicture}[
    node distance=5cm and 4.5cm, 
    auto, 
    thick,
    state/.style={circle, draw, minimum size=1.5cm},
    accepting/.style={double}
]
    % Positioned nodes with significantly increased spacing
    \node[state, initial, fill=blue!10] (q0) at (0,0) {$q_0$};
    \node[state, fill=yellow!10] (q1) at (5,0) {$q_1$};
    \node[state, fill=orange!10] (q2) at (5,3) {$q_2$}; % Positioned directly above q1
    \node[state, accepting, fill=green!10] (q3) at (10,0) {$q_3$};
    
    % Transitions with improved paths to exactly match the image
    \draw[->, thick] (q0) -- node[above] {\texttt{\"}} (q1);
    \draw[->, thick] (q1) edge[loop below] node {any except \texttt{\"} or \texttt{\\}} (q1);
    \draw[->, thick] (q1) to[out=90, in=270] node[left] {\texttt{\\}} (q2);
    \draw[->, thick] (q2) to[out=330, in=45] node[right] {any character} (q1);
    \draw[->, thick] (q1) -- node[above] {\texttt{\"}} (q3);
    
    % Legend with improved positioning
    \node[anchor=north] at (5,-2.5) {
        \begin{tabular}{l}
            \textbf{States:} \\
            $q_0$: Start \\
            $q_1$: Inside string \\
            $q_2$: Escape sequence \\
            $q_3$: End of string (accepting)
        \end{tabular}
    };
\end{tikzpicture}
\caption{DFA for string literal recognition}
\end{figure}

This DFA recognizes:
\begin{itemize}
    \item Simple strings: \texttt{"Hello world"}
    \item Strings with escape sequences: \texttt{"Line1\textbackslash nLine2"}
    \item Empty strings: \texttt{""}
\end{itemize}

\subsection{Comment Recognition DFA}

The scanner recognizes both single-line and multi-line comments using the following DFA:

\begin{figure}[H]
\centering
\begin{tikzpicture}[
    node distance=4.5cm and 4cm, 
    auto, 
    thick,
    state/.style={circle, draw, minimum size=1.5cm},
    accepting/.style={double}
]
    % Nodes with greatly increased spacing using explicit coordinates
    \node[state, initial, fill=blue!10] (q0) at (0,0) {$q_0$};
    \node[state, fill=yellow!10] (q1) at (4,0) {$q_1$};
    \node[state, accepting, fill=green!10] (q2) at (7,3) {$q_2$};
    \node[state, fill=orange!10] (q3) at (7,-3) {$q_3$};
    \node[state, fill=purple!10] (q4) at (11,-3) {$q_4$};
    \node[state, accepting, fill=green!10] (q5) at (15,-3) {$q_5$};
    
    % Transitions with improved path routing to avoid crossing nodes
    \draw[->, thick] (q0) -- node[above] {/} (q1);
    \draw[->, thick] (q1) to[out=45, in=180] node[above] {/} (q2);
    \draw[->, thick] (q1) to[out=315, in=180] node[below] {*} (q3);
    \draw[->, thick] (q2) edge[loop above] node {any except \textbackslash n} (q2);
    \draw[->, thick] (q2) to[out=150, in=90, looseness=1.2] node[above] {\textbackslash n} (q0);
    \draw[->, thick] (q3) edge[loop below] node {any except *} (q3);
    \draw[->, thick] (q3) -- node[above] {*} (q4);
    \draw[->, thick] (q4) edge[loop below] node {*} (q4);
    \draw[->, thick] (q4) -- node[above] {/} (q5);
    \draw[->, thick] (q4) to[out=225, in=315, looseness=1.2] node[below] {any except * or /} (q3);
    % Long transition from q5 to q0 going below all other states
    \draw[->, thick] (q5) to[out=270, in=270, looseness=1.8] node[below] {/} (q0);
    
    \node[anchor=west] at (7,0) {
        \begin{tabular}{l}
            \textbf{Comment Types:} \\
            - Single-line: \texttt{// comment} \\
            - Multi-line: \texttt{/* comment */}
        \end{tabular}
    };
\end{tikzpicture}
\caption{DFA for comment recognition}
\end{figure}

States in the comment DFA:
\begin{itemize}
    \item $q_0$: Initial state
    \item $q_1$: Encountered first /
    \item $q_2$: In single-line comment
    \item $q_3$: In multi-line comment
    \item $q_4$: Potentially ending multi-line comment
    \item $q_5$: End of multi-line comment
\end{itemize}

\section{Assumptions Made Beyond the Basic Language Description}

In implementing our scanner, we made several assumptions and design decisions that go beyond the basic C language specification:

\begin{enumerate}
    \item \textbf{Multi-character Constants}: The scanner accepts multi-character constants like \texttt{'xy'} even though they're not standard C, treating them as valid character literals.
    
    \item \textbf{Nested Comments}: The scanner handles nested comments like \texttt{/* outer /* inner */ outer */} by ignoring everything until the first closing \texttt{*/} is found.
    
    \item \textbf{Identifier Length}: No limit is enforced on identifier length, allowing arbitrarily long identifiers.
    
    \item \textbf{Type Qualifiers}: Type qualifiers like \texttt{const} and \texttt{volatile} are treated as regular keywords rather than as part of type declarations.
    
    \item \textbf{Symbol Table Information}: The scanner tracks additional information beyond basic token recognition, including variable types, function parameters, array dimensions, and usage frequency.
    
    \item \textbf{Variable-Constant Association}: The scanner associates constants with the variables they are assigned to, which is not a requirement of a basic lexical analyzer.
\end{enumerate}

\subsection{Test Case 1: Valid C Code}

\begin{verbatim}
// Test Case 1: Valid C code
#include <stdio.h>
int main() {
    int a = 10;
    float b = 20.5;
    char c = 'x';
    printf("Hello World\n");
    return 0;
}
\end{verbatim}

\noindent
\textbf{Output:}
\begin{verbatim}
[line 2] PREPROC      : #include <stdio.h>
[line 3] TYPE         : int
[line 3] IDENT        : main
[line 3] PUNCT        : (
[line 3] PUNCT        : {
[line 4] TYPE         : int
[line 4] IDENT        : a
[line 4] OP           : =
[line 4] NUMBER       : 10
[line 4] PUNCT        : ;
...

==== SYMBOL TABLE ====
Name                 Type            Dimensions   Frequency  Return Type
a                    int             -            1          -
b                    float           -            1          -
c                    char            -            1          -
printf               -               -            1          -
main                 int             -            1          int

==== CONSTANT TABLE ====
Variable Name        Line No.   Value                          Type
a                    4          10                             int
b                    5          20.5                           float
c                    6          'x'                            char
-                    8          0                              int
\end{verbatim}

\subsection{Test Case 2: Invalid Tokens}

\begin{verbatim}
// Test Case 2: Invalid tokens and errors
#include <stdio.h>
int main() {
    int a = 10$;
    float b = 20.5.3;
    char c = 'xy';
    printf("Hello World\n");
    return 0;
}
\end{verbatim}

\noindent
\textbf{Output (showing error detection):}
\begin{verbatim}
[line 4] TYPE         : int
[line 4] IDENT        : a
[line 4] OP           : =
[line 4] NUMBER       : 10
[line 4] ERROR: Invalid token '$'
[line 5] TYPE         : float
[line 5] IDENT        : b
[line 5] OP           : =
[line 5] ERROR: Invalid float literal '20.5.3'
\end{verbatim}

\subsection{Test Case 3: Comments}

\begin{verbatim}
// Test Case 3: Comments and nested comments
#include <stdio.h>
/* This is a comment
   /* Nested comment */
   End of comment */
int main() {
    // Single line comment
    int x = 42;
    return 0;
}
\end{verbatim}

\noindent
\textbf{Output (comments correctly ignored):}
\begin{verbatim}
[line 2] PREPROC      : #include <stdio.h>
[line 6] TYPE         : int
[line 6] IDENT        : main
...
\end{verbatim}

\subsection{Test Case 4: Function Definitions and Calls}

\begin{verbatim}
// Example function definition and calls
int multiply(int x, int y) {
    return x * y;
}

int main() {
    int product = multiply(6, 7);
    return 0;
}
\end{verbatim}

\noindent
\textbf{Output (showing function tracking):}
\begin{verbatim}
==== SYMBOL TABLE ====
Name                 Type         Frequency  Return Type  Parameters Lists
multiply             int          2          int          int x, int y ; 6, 7
product              int          1          -            -
main                 int          1          int          -
\end{verbatim}

\section{Handling of Comments, Strings, and Errors}

\subsection{Comment Handling}

The scanner supports two types of comments:
\begin{enumerate}
    \item \textbf{Single-line comments} (\texttt{// comment}): Matched by the pattern \texttt{//.*/} and simply ignored.
    \item \textbf{Multi-line comments} (\texttt{/* comment */}): Handled using a special lexical state \texttt{COMMENT}. When \texttt{/*} is encountered, the scanner enters the \texttt{COMMENT} state and ignores all input until it finds \texttt{*/}.
\end{enumerate}

Nested comments are partially supported. The scanner will exit comment mode upon finding the first \texttt{*/}, potentially leading to syntax errors if nested comments are used improperly.

\subsection{String Handling}

String literals are processed using a dedicated \texttt{STRING} state:
\begin{enumerate}
    \item When a double quote is encountered, the scanner enters the \texttt{STRING} state.
    \item It then collects all characters until a closing double quote is found.
    \item Escape sequences within strings (like \texttt{\textbackslash n}, \texttt{\textbackslash"}) are properly recognized.
    \item Unterminated strings (without closing quotes) generate an error message.
\end{enumerate}

The scanner also supports continued strings across multiple lines using backslash-newline sequences.

\subsection{Error Handling}

The scanner implements several error detection mechanisms:
\begin{enumerate}
    \item \textbf{Invalid tokens}: Characters that don't match any defined pattern are reported as errors with line numbers.
    \item \textbf{Malformed numbers}: Invalid numeric formats (like \texttt{20.5.3}) are flagged as errors.
    \item \textbf{Unterminated strings/comments}: The scanner detects and reports strings without closing quotes.
\end{enumerate}

Errors are reported to stderr with the line number and the invalid token:
\begin{verbatim}
[line 4] ERROR: Invalid token '$'
\end{verbatim}

The scanner continues processing after encountering errors, allowing it to find multiple errors in a single pass.

\section{Conclusion}

Our lexical analyzer for the C programming language successfully meets all the requirements for a robust scanner. It correctly identifies all C language tokens, maintains detailed symbol and constant tables, tracks context for declarations, assignments, and function calls, reports errors for invalid tokens, and handles complex constructs like strings, comments, and function arguments.

The implementation uses efficient data structures and algorithms, particularly a hash-based symbol table that provides O(1) lookup time. The scanner's modular design and clear documentation make it maintainable and extendable for future enhancements.

Recent improvements, such as associating constants with their variable names, provide additional functionality beyond the basic requirements of a lexical analyzer. These features make our scanner not just a token recognizer but also a valuable tool for gathering information that would be useful in subsequent compilation phases.

\section{References}

\begin{enumerate}
    \item Aho, A. V., Lam, M. S., Sethi, R., \& Ullman, J. D. (2006). Compilers: Principles, Techniques, and Tools (2nd Edition). Addison Wesley.
    \item Levine, J., Mason, T., \& Brown, D. (1992). Lex \& Yacc (2nd Edition). O'Reilly Media.
    \item Flex Manual: https://westes.github.io/flex/manual/
    \item C Language Specification: https://www.open-std.org/jtc1/sc22/wg14/
\end{enumerate}
   
    
\end{document}
